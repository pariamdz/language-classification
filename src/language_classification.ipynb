{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm6AVjA437Ha",
        "outputId": "877d3461-33bf-4dcd-ea3f-376d7115ae2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9O5yT2rwpOF",
        "outputId": "6306a831-ea4a-4125-b5d4-9bce7372c108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (22593, 2)\n",
            "preprocessing\n",
            "(14692, 3)\n",
            "Loading in word vectors...\n",
            "Finished loading in word vectors\n",
            "Numer of samples with no words found: 194 / 11753\n",
            "Numer of samples with no words found: 38 / 2939\n",
            "classification_report of KNN\n",
            "on Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5605\n",
            "           1       1.00      1.00      1.00      6148\n",
            "\n",
            "    accuracy                           1.00     11753\n",
            "   macro avg       1.00      1.00      1.00     11753\n",
            "weighted avg       1.00      1.00      1.00     11753\n",
            "\n",
            "on Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      1402\n",
            "           1       0.97      0.93      0.95      1537\n",
            "\n",
            "    accuracy                           0.95      2939\n",
            "   macro avg       0.95      0.95      0.95      2939\n",
            "weighted avg       0.95      0.95      0.95      2939\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "def preprocess(df):\n",
        "\n",
        "  print('preprocessing')\n",
        "  df['text']=df.textcontent.apply(lambda x :re.sub(r'[^\\w\\s]',' ',str(x)))\n",
        "  df.text=df.text.apply(lambda x : re.sub(r'[^\\u0600-\\u06FF\\s]+',' ',str(x)))\n",
        "  df.text=df.text.apply(lambda x : re.sub(r'[\\u06F0-\\u06F9]',' ',str(x)))\n",
        "  df.text=df.text.apply(lambda x : re.sub(r'[\\u0660-\\u0669]',' ',str(x)))\n",
        "  df.text=df.text.apply(lambda x : re.sub(r'\\s{2,}',' ',str(x)))\n",
        "  df.text=df.text.apply(lambda x : re.sub(r'[\\u200c]',' ',str(x)))\n",
        "\n",
        "  return df\n",
        "\n",
        "class Word2VecVectorizer:\n",
        "  def __init__(self, model,embedding_size):\n",
        "    print(\"Loading in word vectors...\")\n",
        "    self.word_vectors = model\n",
        "    self.embedding_size=embedding_size\n",
        "    print(\"Finished loading in word vectors\")\n",
        "\n",
        "  def fit(self, data):\n",
        "    pass\n",
        "\n",
        "  def transform(self, data):\n",
        "    X = np.zeros((len(data), self.embedding_size))\n",
        "    n = 0\n",
        "    emptycount = 0\n",
        "    for sentence in data:\n",
        "      tokens = sentence.split(' ')\n",
        "      vecs = []\n",
        "      m = 0\n",
        "      for word in tokens:\n",
        "        try:\n",
        "          vec = self.word_vectors[word]\n",
        "          vecs.append(vec)\n",
        "          m += 1\n",
        "        except KeyError:\n",
        "          pass\n",
        "      if len(vecs) > 0:\n",
        "        vecs = np.array(vecs)\n",
        "        X[n] = vecs.mean(axis=0)\n",
        "      else:\n",
        "        emptycount += 1\n",
        "      n += 1\n",
        "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
        "    return X\n",
        "\n",
        "  def fit_transform(self, data):\n",
        "    self.fit(data)\n",
        "    return self.transform(data)\n",
        "\n",
        "def language_detect():\n",
        "\n",
        "  data=pd.read_excel(\"new_final_dataset.xlsx\",engine=\"openpyxl\")[['textcontent','target']]\n",
        "  print(\"shape:\",data.shape)\n",
        "  data = preprocess(data)\n",
        "  data.drop_duplicates(subset=['text'],keep='first',inplace=True)\n",
        "  data.dropna(inplace=True)\n",
        "  print(data.shape)\n",
        "\n",
        "  x=data.text\n",
        "  y=data.target\n",
        "\n",
        "  x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y,shuffle=True)\n",
        "\n",
        "  from gensim.models.keyedvectors import KeyedVectors\n",
        "  file_path = '/content/drive/MyDrive/insta_wchr.vec'\n",
        "  model = KeyedVectors.load_word2vec_format(file_path)\n",
        "\n",
        "  vectorizer = Word2VecVectorizer(model,100)\n",
        "  x_train_cv = vectorizer.fit_transform(x_train)\n",
        "  x_test_cv= vectorizer.transform(x_test)\n",
        "\n",
        "  #KNN\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  KNN = KNeighborsClassifier()\n",
        "  param_grid = {\n",
        "      'n_neighbors': [3, 5, 7],\n",
        "      'weights': ['uniform', 'distance'],\n",
        "      'metric': ['euclidean', 'manhattan']\n",
        "    }\n",
        "  grid_search = GridSearchCV(KNN, param_grid, cv=5)\n",
        "  grid_search.fit(x_train_cv, y_train)\n",
        "  best_knn = grid_search.best_estimator_\n",
        "  best_knn.fit(x_train_cv, y_train)\n",
        "  y_train_pred = best_knn.predict(x_train_cv)\n",
        "  y_test_pred = best_knn.predict(x_test_cv)\n",
        "  report_train = classification_report(y_train, y_train_pred)\n",
        "  report_test = classification_report(y_test, y_test_pred)\n",
        "  print(\"classification_report of KNN\")\n",
        "  print(\"on Train\")\n",
        "  print(report_train)\n",
        "  print(\"on Test\")\n",
        "  print(report_test)\n",
        "\n",
        "  with open('KNN_model.pkl','wb') as f_KNN:\n",
        "      pickle.dump(best_knn,f_KNN)\n",
        "\n",
        "language_detect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AWgCotSejeBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}